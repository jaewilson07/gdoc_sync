{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: utils.html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "> supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "import os\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import re\n",
    "import pathlib\n",
    "import unicodedata\n",
    "import json\n",
    "import chardet\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import MarkdownConverter\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pptx2md\n",
    "\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse as dtu_parse\n",
    "\n",
    "from dotenv import set_key, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/gdoc_sync/nbs/utils.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsolid-enigma-9gg59jrxvw3p744/workspaces/gdoc_sync/nbs/utils.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdomolibrary_extensions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauth\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mga\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsolid-enigma-9gg59jrxvw3p744/workspaces/gdoc_sync/nbs/utils.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m GOOGLE_AUTH_ENV_PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.env\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bsolid-enigma-9gg59jrxvw3p744/workspaces/gdoc_sync/nbs/utils.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(GOOGLE_AUTH_ENV_PATH)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsolid-enigma-9gg59jrxvw3p744/workspaces/gdoc_sync/nbs/utils.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m load_dotenv(GOOGLE_AUTH_ENV_PATH)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import domolibrary_extensions.google.auth as ga\n",
    "\n",
    "GOOGLE_AUTH_ENV_PATH = \".env\"\n",
    "assert os.path.exists(GOOGLE_AUTH_ENV_PATH)\n",
    "\n",
    "load_dotenv(GOOGLE_AUTH_ENV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codespace Mangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "default_keys = ['DOCKER_BUILDKIT',\n",
    " 'ENABLE_DYNAMIC_INSTALL',\n",
    " 'LESSOPEN',\n",
    " 'GIT_COMMITTER_NAME',\n",
    " 'PYTHONIOENCODING',\n",
    " 'GITHUB_CODESPACE_TOKEN',\n",
    " 'USER',\n",
    " 'RVM_PATH',\n",
    " 'NVS_ROOT',\n",
    " 'HOSTNAME',\n",
    " 'DOTNET_USE_POLLING_FILE_WATCHER',\n",
    " 'CONDA_SCRIPT',\n",
    " 'PIPX_HOME',\n",
    " 'SHLVL',\n",
    " 'GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN',\n",
    " 'GCP_KEY',\n",
    " 'HUGO_ROOT',\n",
    " 'HOME',\n",
    " 'OLDPWD',\n",
    " 'ORYX_ENV_TYPE',\n",
    " 'NVM_BIN',\n",
    " 'CODESPACES',\n",
    " 'DOTNET_RUNNING_IN_CONTAINER',\n",
    " 'NVM_SYMLINK_CURRENT',\n",
    " 'DYNAMIC_INSTALL_ROOT_DIR',\n",
    " 'PIPX_BIN_DIR',\n",
    " 'NVM_INC',\n",
    " 'rvm_stored_umask',\n",
    " 'ORYX_DIR',\n",
    " 'GRADLE_HOME',\n",
    " 'rvm_user_install_flag',\n",
    " 'MAVEN_HOME',\n",
    " 'GOROOT',\n",
    " 'NODE_ROOT',\n",
    " 'GITHUB_GRAPHQL_URL',\n",
    " 'GITHUB_USER',\n",
    " 'NVM_DIR',\n",
    " 'PYTHON_PATH',\n",
    " 'DOTNET_SKIP_FIRST_TIME_EXPERIENCE',\n",
    " 'ContainerVersion',\n",
    " 'NVS_HOME',\n",
    " 'GITHUB_API_URL',\n",
    " 'rvm_bin_path',\n",
    " 'SDKMAN_CANDIDATES_API',\n",
    " '_',\n",
    " 'RUBY_VERSION',\n",
    " 'PROMPT_DIRTRIM',\n",
    " 'IRBRC',\n",
    " 'CLOUDENV_ENVIRONMENT_ID',\n",
    " 'DOTNET_ROOT',\n",
    " 'NVS_DIR',\n",
    " 'PHP_ROOT',\n",
    " 'PATH',\n",
    " 'JAVA_ROOT',\n",
    " 'VSCODE_AGENT_FOLDER',\n",
    " 'SDKMAN_CANDIDATES_DIR',\n",
    " 'HUGO_DIR',\n",
    " 'NPM_GLOBAL',\n",
    " 'SHELL_LOGGED_IN',\n",
    " 'MY_RUBY_HOME',\n",
    " 'LANG',\n",
    " 'SDKMAN_DIR',\n",
    " 'RUBY_ROOT',\n",
    " 'LS_COLORS',\n",
    " 'SDKMAN_PLATFORM',\n",
    " 'GITHUB_REPOSITORY',\n",
    " 'SHELL',\n",
    " 'GOPATH',\n",
    " 'rvm_prefix',\n",
    " 'rvm_loaded_flag',\n",
    " 'GEM_HOME',\n",
    " 'ORYX_PREFER_USER_INSTALLED_SDKS',\n",
    " 'LESSCLOSE',\n",
    " 'ORYX_SDK_STORAGE_BASE_URL',\n",
    " 'CONDA_DIR',\n",
    " 'rvm_version',\n",
    " 'DEBIAN_FLAVOR',\n",
    " 'GIT_COMMITTER_EMAIL',\n",
    " 'GEM_PATH',\n",
    " 'JAVA_HOME',\n",
    " 'NVS_USE_XZ',\n",
    " 'INTERNAL_VSCS_TARGET_URL',\n",
    " 'PWD',\n",
    " 'NVM_CD_FLAGS',\n",
    " 'GITHUB_SERVER_URL',\n",
    " 'PHP_PATH',\n",
    " 'PYTHON_ROOT',\n",
    " 'RAILS_DEVELOPMENT_HOSTS',\n",
    " 'NVS_OS',\n",
    " 'CODESPACE_NAME',\n",
    " 'RUBY_HOME',\n",
    " 'MAVEN_ROOT',\n",
    " 'rvm_path',\n",
    " 'NUGET_XMLDOC_MODE',\n",
    " 'VSCODE_HANDLES_SIGPIPE',\n",
    " 'VSCODE_AMD_ENTRYPOINT',\n",
    " 'VSCODE_HANDLES_UNCAUGHT_ERRORS',\n",
    " 'VSCODE_NLS_CONFIG',\n",
    " 'BROWSER',\n",
    " 'VSCODE_CWD',\n",
    " 'ELECTRON_RUN_AS_NODE',\n",
    " 'VSCODE_IPC_HOOK_CLI',\n",
    " 'VSCODE_L10N_BUNDLE_LOCATION',\n",
    " 'DEBUG',\n",
    " 'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING',\n",
    " 'PYTHONUNBUFFERED',\n",
    " 'PYDEVD_USE_FRAME_EVAL',\n",
    " 'TERM',\n",
    " 'CLICOLOR',\n",
    " 'FORCE_COLOR',\n",
    " 'CLICOLOR_FORCE',\n",
    " 'PAGER',\n",
    " 'GIT_PAGER',\n",
    " 'MPLBACKEND']\n",
    "\n",
    "def export_env(\n",
    "        default_keys,\n",
    "        output_file_path\n",
    "):\n",
    "    keep_keys = [key for key in os.environ.keys() if key not in default_keys]\n",
    "\n",
    "    with open(output_file_path , 'w+') as f:\n",
    "        f.writelines([ f\"{key} = '{value}'\\n\" for key, value in os.environ.items() if key in keep_keys])\n",
    "        f.write(f\"_OUTPUT_DATE = '{dt.datetime.now().strftime('%Y-%m-%d %H:%M')}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_env(default_keys= default_keys,\n",
    "           output_file_path= '../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "\n",
    "def rename_filepath_to_match_datatype(data, file_path):\n",
    "\n",
    "    is_path_ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    old_suffix = pathlib.Path(file_path).suffix if is_path_ext else None\n",
    "\n",
    "    new_suffix = ''\n",
    "\n",
    "    print(type(data))\n",
    "\n",
    "    if isinstance(data, str) or isinstance(data, bytes) or isinstance(data, bytearray) : new_suffix = '.txt'\n",
    "    if isinstance(data, dict) : new_suffix = '.json'\n",
    "\n",
    "    file_path = file_path+new_suffix\n",
    "    \n",
    "    if old_suffix:\n",
    "        file_path = file_path.replace(old_suffix,'')\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'dict'>\n",
      "<class 'bytes'>\n",
      "<class 'bytearray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/pankaj/abc.txt',\n",
       " '/Users/pankaj/abc.json',\n",
       " '/Users/pankaj/abc.txt',\n",
       " '/Users/pankaj/abc.txt']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = [ \"hello world\" , {\"a\" : \"b\"}, b'\\xC3\\xA9', bytearray(b'\\x02\\x03\\x05\\x07')]\n",
    "\n",
    "[rename_filepath_to_match_datatype(test, \"/Users/pankaj/abc\") for test in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def detect_encoding(file_path, debug_prn: bool = False):\n",
    "    detector = chardet.universaldetector.UniversalDetector()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for line in f:\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "    detector.close()\n",
    "\n",
    "    encoding = detector.result\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_encoding(\"./utils.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def read_html_file(\n",
    "    file_path, is_convert_to_soup: bool = True\n",
    ") -> Union[str, BeautifulSoup]:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(file_path)\n",
    "\n",
    "    page_encoding = detect_encoding(file_path)\n",
    "\n",
    "    with open(file_path, encoding=page_encoding[\"encoding\"]) as fp:\n",
    "        if is_convert_to_soup:\n",
    "            return BeautifulSoup(fp, \"lxml\")\n",
    "\n",
    "        return fp.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def remove_query_params_from_url(url):\n",
    "    u = urlparse(url)\n",
    "    return urljoin(url, urlparse(url).path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://domo-support.domo.com/s/article/36004740075',\n",
       " 'https://domo-support.domo.com/s/topic/0TO5w000000ZlOmGAK/20202023',\n",
       " 'https://domo-support.domo.com/s/topic/0TO5w000000Zan7GAC/archived-feature-release-notes',\n",
       " 'https://domo-support.domo.com/s/knowledge-base']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_urls = [\n",
    "    \"https://domo-support.domo.com/s/article/36004740075\",\n",
    "    \"https://domo-support.domo.com/s/topic/0TO5w000000ZlOmGAK/20202023\",  # list of articles\n",
    "    \"https://domo-support.domo.com/s/topic/0TO5w000000Zan7GAC/archived-feature-release-notes\",  # list of topics\n",
    "    \"https://domo-support.domo.com/s/knowledge-base\",\n",
    "]\n",
    "\n",
    "[remove_query_params_from_url(url) for url in test_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def update_env(env_path: str, key: str, value: str, debug_prn: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    updates a .env file with a key value pair\n",
    "    then reloads the env_file\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(env_path):\n",
    "        with open(env_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "    quote_mode = \"always\"\n",
    "\n",
    "    if isinstance(value, dict):\n",
    "        quote_mode = \"never\"\n",
    "        value = json.dumps(value)\n",
    "\n",
    "    if debug_prn:\n",
    "        from pprint import pprint\n",
    "\n",
    "        pprint(\n",
    "            {\n",
    "                \"env_path\": env_path,\n",
    "                \"key\": key,\n",
    "                \"value\": value,\n",
    "                \"type\": type(value),\n",
    "                \"quote_mode\": quote_mode,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    set_key(env_path, key, value, quote_mode=quote_mode)\n",
    "\n",
    "    set_key(env_path, \"env_last_modified\", f\"updated - {dt.date.today()}\")\n",
    "\n",
    "    load_dotenv(env_path, override=True)\n",
    "\n",
    "    return {key: os.getenv(key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def upsert_folder(folder_path: str, debug_prn: bool = False):\n",
    "    folder_path = os.path.dirname(folder_path)\n",
    "\n",
    "    if debug_prn:\n",
    "        print(\n",
    "            {\n",
    "                \"upsert_folder\": os.path.abspath(folder_path),\n",
    "                \"is_exist\": os.path.exists(folder_path),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "\n",
    "\n",
    "def get_all_files_and_folders(\n",
    "    directory, file_type=None  # to only retrieve a specific file type\n",
    ") -> Union[Tuple, List]:\n",
    "    \"\"\"walk a directory and retrieve a list of files and a list of directory\n",
    "    returns Tuple of file_ls , dir_ls OR file_ls if file_type supplied\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        raise FileNotFoundError(directory)\n",
    "\n",
    "    file_ls = []\n",
    "    dir_ls = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if file_type:\n",
    "                if not name.lower().endswith(file_type.lower()):\n",
    "                    continue\n",
    "            file_ls.append(os.path.join(root, name))\n",
    "\n",
    "        if file_type:\n",
    "            continue\n",
    "\n",
    "        for name in dirs:\n",
    "            dir_ls.append(os.path.join(root, name))\n",
    "\n",
    "    if file_type:\n",
    "        return file_ls\n",
    "\n",
    "    return file_ls, dir_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/epic/10002.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/1.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/3/epic.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/3/issue.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/api/2/myself.json']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function\n",
    "get_all_files_and_folders(\"./jira\", \".json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle converting Files to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "\n",
    "class ImageBlockConverter(MarkdownConverter):\n",
    "    \"\"\"\n",
    "    Create a custom MarkdownConverter that adds two newlines after an image\n",
    "    \"\"\"\n",
    "\n",
    "    def convert_img(self, el, text, convert_as_inline, is_resize: bool = True):\n",
    "        \"\"\"\n",
    "        custom image downloader for ImabeBlockConverter\n",
    "        will handle resize\n",
    "        \"\"\"\n",
    "\n",
    "        if is_resize:\n",
    "            style_obj = {\n",
    "                (obj.split(\":\")[0].strip()): obj.split(\":\")[1].strip()\n",
    "                for obj in el.get(\"style\").split(\";\")\n",
    "                if \":\" in obj\n",
    "            }\n",
    "\n",
    "            file_path = os.path.join(\n",
    "                os.path.dirname(self.options[\"file_path\"]), el[\"src\"]\n",
    "            )\n",
    "\n",
    "            image = Image.open(file_path)\n",
    "\n",
    "            width = style_obj[\"width\"].replace(\"px\", \"\")\n",
    "            width = int(float(width))\n",
    "\n",
    "            height = style_obj[\"height\"].replace(\"px\", \"\")\n",
    "            height = int(float(height))\n",
    "\n",
    "            new_image = image.resize((width, height))\n",
    "            new_image.save(file_path)\n",
    "\n",
    "        return super().convert_img(el, text, convert_as_inline)\n",
    "\n",
    "\n",
    "def md(html, **options):\n",
    "    \"\"\"Create shorthand method for handling conversion\"\"\"\n",
    "    return ImageBlockConverter(**options).convert(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "def convert_html_to_markdown(file_path):\n",
    "    \"\"\"converts html file to markdown in place\"\"\"\n",
    "\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "\n",
    "    markdown_content = md(\n",
    "        str(html),\n",
    "        keep_inline_images_in=[\"td\", \"span\"],\n",
    "        file_path=file_path,\n",
    "        is_resize=True,\n",
    "    )\n",
    "\n",
    "    md_path = file_path.replace(\".html\", \".md\")\n",
    "\n",
    "    with open(md_path, \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_content)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "\n",
    "def download_zip(zip_bytes_content, output_folder, is_convert_to_markdown: bool = True):\n",
    "    \"\"\"save bytes content to a zip file then convert html to markdown\"\"\"\n",
    "\n",
    "    zip = zipfile.ZipFile(io.BytesIO(zip_bytes_content), \"r\")\n",
    "    zip.extractall(output_folder)\n",
    "\n",
    "    file_ls = os.listdir(output_folder)\n",
    "\n",
    "    # rename the html file to index.html\n",
    "    for file_name in file_ls:\n",
    "        if file_name.endswith(\".html\"):\n",
    "            output_index = os.path.join(output_folder, \"index.html\")\n",
    "            os.replace(os.path.join(output_folder, file_name), output_index)\n",
    "\n",
    "            if is_convert_to_markdown:\n",
    "                convert_html_to_markdown(os.path.join(output_folder, \"index.html\"))\n",
    "\n",
    "    return f\"successfully downloaded zip to {output_folder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of downloading a zip from google docs and converting it to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using saved token\n",
      "generating service object on GoogleAuth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'successfully downloaded zip to ../TEST/utils/drive_converter-download_zip'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import domolibrary_extensions.google.auth as ga\n",
    "\n",
    "\n",
    "DOCUMENT_ID = \"1j7XsbvFy0xUgGL6i-3LSChKvzSmTZSOyimEt6tQS-Kk\"\n",
    "\n",
    "# generates Credentials object\n",
    "google_auth = ga.GoogleAuth.get_creds_from_env(\n",
    "    credentials_env_key=\"GDOC_KEY\",\n",
    "    token_env_key=\"GDOC_TOKEN\",\n",
    ")\n",
    "google_auth\n",
    "content = (\n",
    "    google_auth.service.files()\n",
    "    .export(fileId=DOCUMENT_ID, mimeType=\"application/zip\")\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "download_zip(content, \"../TEST/utils/drive_converter-download_zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "\n",
    "\n",
    "def download_pptx(\n",
    "    pptx_bytes_content, output_folder, is_convert_to_markdown: bool = True\n",
    "):\n",
    "    \"\"\"save bytes content to a pptx file then converts to markdown\"\"\"\n",
    "\n",
    "    upsert_folder(output_folder)\n",
    "\n",
    "    output_ppt_index = os.path.join(output_folder, \"index.pptx\")\n",
    "\n",
    "    with open(output_ppt_index, \"wb+\") as binary_file:\n",
    "        # Write bytes to file\n",
    "        binary_file.write(pptx_bytes_content)\n",
    "\n",
    "    if is_convert_to_markdown:\n",
    "        pptx2md.convert(\n",
    "            output_ppt_index,\n",
    "            output=os.path.join(output_folder, \"index.md\"),\n",
    "            image_dir=os.path.join(output_folder, \"images\"),\n",
    "        )\n",
    "\n",
    "    return f\"successfully downloaded content to {output_folder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of download pptx from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using saved token\n",
      "generating service object on GoogleAuth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting slides: 100%|██████████| 2/2 [00:00<00:00, 1045.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'successfully downloaded content to ./TEST/utils/drive_converter-download_pptx'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | import domolibrary_extensions.google.auth as ga\n",
    "\n",
    "SLIDE_ID = \"1_k4NRraKI1TmHNlpQCuqJrWr6dP7DNracdMCtfN8XlM\"\n",
    "\n",
    "# generates Credentials object\n",
    "google_auth = ga.GoogleAuth.get_creds_from_env(\n",
    "    credentials_env_key=\"GDOC_KEY\", token_env_key=\"GDOC_TOKEN\"\n",
    ")\n",
    "\n",
    "content = (\n",
    "    google_auth.service.files()\n",
    "    .export(\n",
    "        fileId=SLIDE_ID,\n",
    "        mimeType=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\",\n",
    "    )\n",
    "    .execute()\n",
    ")\n",
    "download_pptx(content, \"./TEST/utils/drive_converter-download_pptx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_to_snake_case(text_str):\n",
    "    \"\"\"converts 'snake_case_str' to 'snakeCaseStr'\"\"\"\n",
    "\n",
    "    return text_str.replace(\" \", \"_\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_remove_accents(text_str: str) -> str:\n",
    "    return \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFD\", text_str)\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('est etre', 'kozuscek')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_remove_accents(\"est être\"), convert_str_remove_accents(\"kožušček\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_keep_alphanumeric(text_str) -> str:\n",
    "    pattern = \"[^0-9a-zA-Z_\\s]+\"\n",
    "\n",
    "    return re.sub(pattern, \"\", text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_file_name(text_str: str) -> str:\n",
    "    \"\"\"convert strings to clean file name or url\"\"\"\n",
    "\n",
    "    return convert_str_keep_alphanumeric(\n",
    "        convert_str_to_snake_case(convert_str_remove_accents(text_str))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('register_snowflake_with_cloud_amplifier', 'kozuscek_and_beast_modes')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_file_name(\"Register Snowflake with Cloud Amplifier\"), convert_str_file_name(\n",
    "    \"Kožušček and Beast Modes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_to_date(datefield: str) -> dt.datetime:\n",
    "    \"\"\"converts string date to datetime object\"\"\"\n",
    "    return dtu_parse(datefield) if datefield else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 10, 1, 0, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_to_date(\"2023-10-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export(\"utils.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
