{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: utils.html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "> supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "import os\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "import json\n",
    "import chardet\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import MarkdownConverter\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pptx2md\n",
    "\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse as dtu_parse\n",
    "\n",
    "from dotenv import set_key, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import gdoc_sync.google.auth as ga\n",
    "\n",
    "GOOGLE_AUTH_ENV_PATH = \".env\"\n",
    "assert os.path.exists(GOOGLE_AUTH_ENV_PATH)\n",
    "\n",
    "load_dotenv(GOOGLE_AUTH_ENV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def detect_encoding(file_path, debug_prn: bool = False):\n",
    "    detector = chardet.universaldetector.UniversalDetector()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for line in f:\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "    detector.close()\n",
    "\n",
    "    encoding = detector.result\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_encoding(\"./utils.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def read_html_file(\n",
    "    file_path, is_convert_to_soup: bool = True\n",
    "    \n",
    ") -> Union[str, BeautifulSoup]:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(file_path)\n",
    "\n",
    "    page_encoding = detect_encoding(file_path)\n",
    "\n",
    "    with open(file_path, encoding=page_encoding[\"encoding\"]) as fp:\n",
    "\n",
    "        if is_convert_to_soup:\n",
    "            return BeautifulSoup(fp, \"lxml\")\n",
    "\n",
    "        return fp.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def remove_query_params_from_url(url):\n",
    "    u = urlparse(url)\n",
    "    return urljoin(url, urlparse(url).path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://domo-support.domo.com/s/article/36004740075',\n",
       " 'https://domo-support.domo.com/s/topic/0TO5w000000ZlOmGAK/20202023',\n",
       " 'https://domo-support.domo.com/s/topic/0TO5w000000Zan7GAC/archived-feature-release-notes',\n",
       " 'https://domo-support.domo.com/s/knowledge-base']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_urls = [\n",
    "    \"https://domo-support.domo.com/s/article/36004740075\",\n",
    "    \"https://domo-support.domo.com/s/topic/0TO5w000000ZlOmGAK/20202023\",  # list of articles\n",
    "    \"https://domo-support.domo.com/s/topic/0TO5w000000Zan7GAC/archived-feature-release-notes\",  # list of topics\n",
    "    \"https://domo-support.domo.com/s/knowledge-base\",\n",
    "]\n",
    "\n",
    "[remove_query_params_from_url(url) for url in test_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def update_env(env_path: str, key: str, value: str, debug_prn: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    updates a .env file with a key value pair\n",
    "    then reloads the env_file\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(env_path):\n",
    "        with open(env_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "    quote_mode = \"always\"\n",
    "\n",
    "    if isinstance(value, dict):\n",
    "        quote_mode = \"never\"\n",
    "        value = json.dumps(value)\n",
    "\n",
    "    if debug_prn:\n",
    "        from pprint import pprint\n",
    "\n",
    "        pprint(\n",
    "            {\n",
    "                \"env_path\": env_path,\n",
    "                \"key\": key,\n",
    "                \"value\": value,\n",
    "                \"type\": type(value),\n",
    "                \"quote_mode\": quote_mode,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    set_key(env_path, key, value, quote_mode=quote_mode)\n",
    "\n",
    "    set_key(env_path, \"env_last_modified\", f\"updated - {dt.date.today()}\")\n",
    "\n",
    "    load_dotenv(env_path, override=True)\n",
    "\n",
    "    return {key: os.getenv(key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def upsert_folder(folder_path: str, debug_prn: bool = False):\n",
    "\n",
    "    folder_path = os.path.dirname(folder_path)\n",
    "\n",
    "    if debug_prn:\n",
    "        print(\n",
    "            {\n",
    "                \"upsert_folder\": os.path.abspath(folder_path),\n",
    "                \"is_exist\": os.path.exists(folder_path),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "\n",
    "\n",
    "def get_all_files_and_folders(\n",
    "    directory, file_type=None  # to only retrieve a specific file type\n",
    ") -> Union[Tuple, List]:\n",
    "    \"\"\"walk a directory and retrieve a list of files and a list of directory\n",
    "    returns Tuple of file_ls , dir_ls OR file_ls if file_type supplied\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        raise FileNotFoundError(directory)\n",
    "\n",
    "    file_ls = []\n",
    "    dir_ls = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if file_type:\n",
    "                if not name.lower().endswith(file_type.lower()):\n",
    "                    continue\n",
    "            file_ls.append(os.path.join(root, name))\n",
    "\n",
    "        if file_type:\n",
    "            continue\n",
    "\n",
    "        for name in dirs:\n",
    "            dir_ls.append(os.path.join(root, name))\n",
    "\n",
    "    if file_type:\n",
    "        return file_ls\n",
    "\n",
    "    return file_ls, dir_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/epic/10002.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/1.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/3/epic.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/3/issue.json',\n",
       " './jira/CACHE/onyxreporting_atlassian_net/rest/api/2/myself.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function\n",
    "get_all_files_and_folders(\"./jira\", \".json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle converting Files to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "\n",
    "class ImageBlockConverter(MarkdownConverter):\n",
    "    \"\"\"\n",
    "    Create a custom MarkdownConverter that adds two newlines after an image\n",
    "    \"\"\"\n",
    "\n",
    "    def convert_img(self, el, text, convert_as_inline, is_resize: bool = True):\n",
    "        \"\"\"\n",
    "        custom image downloader for ImabeBlockConverter\n",
    "        will handle resize\n",
    "        \"\"\"\n",
    "\n",
    "        if is_resize:\n",
    "            style_obj = {\n",
    "                (obj.split(\":\")[0].strip()): obj.split(\":\")[1].strip()\n",
    "                for obj in el.get(\"style\").split(\";\")\n",
    "                if \":\" in obj\n",
    "            }\n",
    "\n",
    "            file_path = os.path.join(\n",
    "                os.path.dirname(self.options[\"file_path\"]), el[\"src\"]\n",
    "            )\n",
    "\n",
    "            image = Image.open(file_path)\n",
    "\n",
    "            width = style_obj[\"width\"].replace(\"px\", \"\")\n",
    "            width = int(float(width))\n",
    "\n",
    "            height = style_obj[\"height\"].replace(\"px\", \"\")\n",
    "            height = int(float(height))\n",
    "\n",
    "            new_image = image.resize((width, height))\n",
    "            new_image.save(file_path)\n",
    "\n",
    "        return super().convert_img(el, text, convert_as_inline)\n",
    "\n",
    "\n",
    "def md(html, **options):\n",
    "    \"\"\"Create shorthand method for handling conversion\"\"\"\n",
    "    return ImageBlockConverter(**options).convert(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "def convert_html_to_markdown(file_path):\n",
    "    \"\"\"converts html file to markdown in place\"\"\"\n",
    "\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "\n",
    "    markdown_content = md(\n",
    "        str(html),\n",
    "        keep_inline_images_in=[\"td\", \"span\"],\n",
    "        file_path=file_path,\n",
    "        is_resize=True,\n",
    "    )\n",
    "\n",
    "    md_path = file_path.replace(\".html\", \".md\")\n",
    "\n",
    "    with open(md_path, \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_content)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "\n",
    "def download_zip(zip_bytes_content, output_folder, is_convert_to_markdown: bool = True):\n",
    "    \"\"\"save bytes content to a zip file then convert html to markdown\"\"\"\n",
    "\n",
    "    zip = zipfile.ZipFile(io.BytesIO(zip_bytes_content), \"r\")\n",
    "    zip.extractall(output_folder)\n",
    "\n",
    "    file_ls = os.listdir(output_folder)\n",
    "\n",
    "    # rename the html file to index.html\n",
    "    for file_name in file_ls:\n",
    "        if file_name.endswith(\".html\"):\n",
    "            output_index = os.path.join(output_folder, \"index.html\")\n",
    "            os.replace(os.path.join(output_folder, file_name), output_index)\n",
    "\n",
    "            if is_convert_to_markdown:\n",
    "                convert_html_to_markdown(os.path.join(output_folder, \"index.html\"))\n",
    "\n",
    "    return f\"successfully downloaded zip to {output_folder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of downloading a zip from google docs and converting it to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using saved token\n",
      "refreshing creds using saved token\n",
      "generating service object on GoogleAuth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'successfully downloaded zip to ../TEST/utils/drive_converter-download_zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gdoc_sync.google.auth as ga\n",
    "\n",
    "\n",
    "DOCUMENT_ID = \"1j7XsbvFy0xUgGL6i-3LSChKvzSmTZSOyimEt6tQS-Kk\"\n",
    "\n",
    "# generates Credentials object\n",
    "google_auth = ga.GoogleAuth.get_creds_from_env(\n",
    "    credentials_env_key=\"GDOC_KEY\",\n",
    "    token_env_key=\"GDOC_TOKEN\",\n",
    ")\n",
    "google_auth\n",
    "content = (\n",
    "    google_auth.service.files()\n",
    "    .export(fileId=DOCUMENT_ID, mimeType=\"application/zip\")\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "download_zip(content, \"../TEST/utils/drive_converter-download_zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "\n",
    "\n",
    "def download_pptx(\n",
    "    pptx_bytes_content, output_folder, is_convert_to_markdown: bool = True\n",
    "):\n",
    "    \"\"\"save bytes content to a pptx file then converts to markdown\"\"\"\n",
    "\n",
    "    upsert_folder(output_folder)\n",
    "\n",
    "    output_ppt_index = os.path.join(output_folder, \"index.pptx\")\n",
    "\n",
    "    with open(output_ppt_index, \"wb+\") as binary_file:\n",
    "        # Write bytes to file\n",
    "        binary_file.write(pptx_bytes_content)\n",
    "\n",
    "    if is_convert_to_markdown:\n",
    "        pptx2md.convert(\n",
    "            output_ppt_index,\n",
    "            output=os.path.join(output_folder, \"index.md\"),\n",
    "            image_dir=os.path.join(output_folder, \"images\"),\n",
    "        )\n",
    "\n",
    "    return f\"successfully downloaded content to {output_folder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of download pptx from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using saved token\n",
      "refreshing creds using saved token\n",
      "generating service object on GoogleAuth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting slides: 100%|██████████| 2/2 [00:00<00:00, 608.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'successfully downloaded content to ./TEST/utils/drive_converter-download_pptx'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | import gdoc_sync.google.auth as ga\n",
    "\n",
    "SLIDE_ID = \"1_k4NRraKI1TmHNlpQCuqJrWr6dP7DNracdMCtfN8XlM\"\n",
    "\n",
    "# generates Credentials object\n",
    "google_auth = ga.GoogleAuth.get_creds_from_env(\n",
    "    credentials_env_key=\"GDOC_KEY\", token_env_key=\"GDOC_TOKEN\"\n",
    ")\n",
    "\n",
    "content = (\n",
    "    google_auth.service.files()\n",
    "    .export(\n",
    "        fileId=SLIDE_ID,\n",
    "        mimeType=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\",\n",
    "    )\n",
    "    .execute()\n",
    ")\n",
    "download_pptx(content, \"./TEST/utils/drive_converter-download_pptx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_to_snake_case(text_str):\n",
    "    \"\"\"converts 'snake_case_str' to 'snakeCaseStr'\"\"\"\n",
    "\n",
    "    return text_str.replace(\" \", \"_\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_remove_accents(text_str: str) -> str:\n",
    "    return \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFD\", text_str)\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('est etre', 'kozuscek')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_remove_accents(\"est être\"), convert_str_remove_accents(\"kožušček\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_keep_alphanumeric(text_str) -> str:\n",
    "    pattern = \"[^0-9a-zA-Z_\\s]+\"\n",
    "\n",
    "    return re.sub(pattern, \"\", text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_file_name(text_str: str) -> str:\n",
    "    \"\"\"convert strings to clean file name or url\"\"\"\n",
    "\n",
    "    return convert_str_keep_alphanumeric(\n",
    "        convert_str_to_snake_case(convert_str_remove_accents(text_str))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('register_snowflake_with_cloud_amplifier', 'kozuscek_and_beast_modes')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_file_name(\"Register Snowflake with Cloud Amplifier\"), convert_str_file_name(\n",
    "    \"Kožušček and Beast Modes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_to_date(datefield: str) -> dt.datetime:\n",
    "    \"\"\"converts string date to datetime object\"\"\"\n",
    "    return dtu_parse(datefield) if datefield else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 10, 1, 0, 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_to_date(\"2023-10-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export('utils.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
