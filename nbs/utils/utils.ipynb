{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: utils.html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "> supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from PIL.Image import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "import os\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import re\n",
    "import pathlib\n",
    "import unicodedata\n",
    "import json\n",
    "import chardet\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import MarkdownConverter\n",
    "import PIL\n",
    "\n",
    "import datetime as dt\n",
    "import base64\n",
    "\n",
    "import asyncio\n",
    "\n",
    "import pptx2md\n",
    "\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse as dtu_parse\n",
    "\n",
    "from dotenv import set_key, load_dotenv\n",
    "\n",
    "from nbdev.showdoc import patch_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from dotenv import load_dotenv\n",
    "import domolibrary_extensions.google.auth as ga\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def gather_with_concurrency(\n",
    "    *coros,  # list of coroutines to await\n",
    "    n=60,  # number of open coroutines\n",
    "):\n",
    "    \"\"\"limits the number of open coroutines at a time.\"\"\"\n",
    "\n",
    "    semaphore = asyncio.Semaphore(n)\n",
    "\n",
    "    async def sem_coro(coro):\n",
    "        async with semaphore:\n",
    "            return await coro\n",
    "\n",
    "    return await asyncio.gather(*(sem_coro(c) for c in coros))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "\n",
    "def rename_filepath_to_match_datatype(data, file_path):\n",
    "\n",
    "    is_path_ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    old_suffix = pathlib.Path(file_path).suffix if is_path_ext else None\n",
    "\n",
    "    new_suffix = ''\n",
    "\n",
    "    if isinstance(data, str) or isinstance(data, bytes) or isinstance(data, bytearray) : new_suffix = '.txt'\n",
    "    if isinstance(data, dict) : new_suffix = '.json'\n",
    "\n",
    "    file_path = file_path+new_suffix\n",
    "    \n",
    "    if old_suffix:\n",
    "        file_path = file_path.replace(old_suffix,'')\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'dict'>\n",
      "<class 'bytes'>\n",
      "<class 'bytearray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/pankaj/abc.txt',\n",
       " '/Users/pankaj/abc.json',\n",
       " '/Users/pankaj/abc.txt',\n",
       " '/Users/pankaj/abc.txt']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = [ \"hello world\" , {\"a\" : \"b\"}, b'\\xC3\\xA9', bytearray(b'\\x02\\x03\\x05\\x07')]\n",
    "\n",
    "[rename_filepath_to_match_datatype(test, \"/Users/pankaj/abc\") for test in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def detect_encoding(file_path, debug_prn: bool = False):\n",
    "    detector = chardet.universaldetector.UniversalDetector()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for line in f:\n",
    "            detector.feed(line)\n",
    "            if detector.done:\n",
    "                break\n",
    "    detector.close()\n",
    "\n",
    "    encoding = detector.result\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_encoding(\"./utils.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def read_html_file(\n",
    "    file_path, is_convert_to_soup: bool = True\n",
    ") -> Union[str, BeautifulSoup]:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(file_path)\n",
    "\n",
    "    page_encoding = detect_encoding(file_path)\n",
    "\n",
    "    with open(file_path, encoding=page_encoding[\"encoding\"]) as fp:\n",
    "        if is_convert_to_soup:\n",
    "            return BeautifulSoup(fp, \"lxml\")\n",
    "\n",
    "        return fp.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def remove_query_params_from_url(url):\n",
    "    u = urlparse(url)\n",
    "    return urljoin(url, urlparse(url).path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://domo-support.domo.com/s/article/36004740075',\n",
       " 'https://domo-support.domo.com/s/topic/0TO5w000000ZlOmGAK/20202023',\n",
       " 'https://domo-support.domo.com/s/topic/0TO5w000000Zan7GAC/archived-feature-release-notes',\n",
       " 'https://domo-support.domo.com/s/knowledge-base']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_urls = [\n",
    "    \"https://domo-support.domo.com/s/article/36004740075\",\n",
    "    \"https://domo-support.domo.com/s/topic/0TO5w000000ZlOmGAK/20202023\",  # list of articles\n",
    "    \"https://domo-support.domo.com/s/topic/0TO5w000000Zan7GAC/archived-feature-release-notes\",  # list of topics\n",
    "    \"https://domo-support.domo.com/s/knowledge-base\",\n",
    "]\n",
    "\n",
    "[remove_query_params_from_url(url) for url in test_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def update_env(env_path: str, key: str, value: str, debug_prn: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    updates a .env file with a key value pair\n",
    "    then reloads the env_file\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(env_path):\n",
    "        with open(env_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\")\n",
    "\n",
    "    quote_mode = \"always\"\n",
    "\n",
    "    if isinstance(value, dict):\n",
    "        quote_mode = \"never\"\n",
    "        value = json.dumps(value)\n",
    "\n",
    "    if debug_prn:\n",
    "        from pprint import pprint\n",
    "\n",
    "        pprint(\n",
    "            {\n",
    "                \"env_path\": env_path,\n",
    "                \"key\": key,\n",
    "                \"value\": value,\n",
    "                \"type\": type(value),\n",
    "                \"quote_mode\": quote_mode,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    set_key(env_path, key, value, quote_mode=quote_mode)\n",
    "\n",
    "    set_key(env_path, \"env_last_modified\", f\"updated - {dt.date.today()}\")\n",
    "\n",
    "    load_dotenv(env_path, override=True)\n",
    "\n",
    "    return {key: os.getenv(key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def upsert_folder(folder_path: str, debug_prn: bool = False):\n",
    "    folder_path = os.path.dirname(folder_path)\n",
    "\n",
    "    if debug_prn:\n",
    "        print(\n",
    "            {\n",
    "                \"upsert_folder\": os.path.abspath(folder_path),\n",
    "                \"is_exist\": os.path.exists(folder_path),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "\n",
    "\n",
    "def get_all_files_and_folders(\n",
    "    directory, file_type=None  # to only retrieve a specific file type\n",
    ") -> Union[Tuple, List]:\n",
    "    \"\"\"walk a directory and retrieve a list of files and a list of directory\n",
    "    returns Tuple of file_ls , dir_ls OR file_ls if file_type supplied\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        raise FileNotFoundError(directory)\n",
    "\n",
    "    file_ls = []\n",
    "    dir_ls = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if file_type:\n",
    "                if not name.lower().endswith(file_type.lower()):\n",
    "                    continue\n",
    "            file_ls.append(os.path.join(root, name))\n",
    "\n",
    "        if file_type:\n",
    "            continue\n",
    "\n",
    "        for name in dirs:\n",
    "            dir_ls.append(os.path.join(root, name))\n",
    "\n",
    "    if file_type:\n",
    "        return file_ls\n",
    "\n",
    "    return file_ls, dir_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board.json',\n",
       " '../jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/epic/10002.json',\n",
       " '../jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/1.json',\n",
       " '../jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/3/epic.json',\n",
       " '../jira/CACHE/onyxreporting_atlassian_net/rest/agile/1_0/board/3/issue.json',\n",
       " '../jira/CACHE/onyxreporting_atlassian_net/rest/api/2/myself.json']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function\n",
    "get_all_files_and_folders(\"../jira\", \".json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle converting Files to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "\n",
    "class ImageBlockConverter(MarkdownConverter):\n",
    "    \"\"\"\n",
    "    Create a custom MarkdownConverter that adds two newlines after an image\n",
    "    \"\"\"\n",
    "\n",
    "    def convert_img(self, el, text, convert_as_inline, is_resize: bool = True):\n",
    "        \"\"\"\n",
    "        custom image downloader for ImabeBlockConverter\n",
    "        will handle resize\n",
    "        \"\"\"\n",
    "\n",
    "        if is_resize:\n",
    "            style_obj = {\n",
    "                (obj.split(\":\")[0].strip()): obj.split(\":\")[1].strip()\n",
    "                for obj in el.get(\"style\").split(\";\")\n",
    "                if \":\" in obj\n",
    "            }\n",
    "\n",
    "            file_path = os.path.join(\n",
    "                os.path.dirname(self.options[\"file_path\"]), el[\"src\"]\n",
    "            )\n",
    "\n",
    "            image = PIL.Image.open(file_path)\n",
    "\n",
    "            width = style_obj[\"width\"].replace(\"px\", \"\")\n",
    "            width = int(float(width))\n",
    "\n",
    "            height = style_obj[\"height\"].replace(\"px\", \"\")\n",
    "            height = int(float(height))\n",
    "\n",
    "            new_image = image.resize((width, height))\n",
    "            new_image.save(file_path)\n",
    "\n",
    "        return super().convert_img(el, text, convert_as_inline)\n",
    "\n",
    "\n",
    "def md(html, **options):\n",
    "    \"\"\"Create shorthand method for handling conversion\"\"\"\n",
    "    return ImageBlockConverter(**options).convert(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "def convert_html_to_markdown(file_path):\n",
    "    \"\"\"converts html file to markdown in place\"\"\"\n",
    "\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "\n",
    "    markdown_content = md(\n",
    "        str(html),\n",
    "        keep_inline_images_in=[\"td\", \"span\"],\n",
    "        file_path=file_path,\n",
    "        is_resize=True,\n",
    "    )\n",
    "\n",
    "    md_path = file_path.replace(\".html\", \".md\")\n",
    "\n",
    "    with open(md_path, \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_content)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "\n",
    "\n",
    "def download_zip(zip_bytes_content, output_folder, is_convert_to_markdown: bool = True):\n",
    "    \"\"\"save bytes content to a zip file then convert html to markdown\"\"\"\n",
    "\n",
    "    zip = zipfile.ZipFile(io.BytesIO(zip_bytes_content), \"r\")\n",
    "    zip.extractall(output_folder)\n",
    "\n",
    "    file_ls = os.listdir(output_folder)\n",
    "\n",
    "    # rename the html file to index.html\n",
    "    for file_name in file_ls:\n",
    "        if file_name.endswith(\".html\"):\n",
    "            output_index = os.path.join(output_folder, \"index.html\")\n",
    "            os.replace(os.path.join(output_folder, file_name), output_index)\n",
    "\n",
    "            if is_convert_to_markdown:\n",
    "                convert_html_to_markdown(os.path.join(output_folder, \"index.html\"))\n",
    "\n",
    "    return f\"successfully downloaded zip to {output_folder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of downloading a zip from google docs and converting it to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using saved token\n",
      "refreshing creds using saved token\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f829807b4c0>: Failed to resolve 'oauth2.googleapis.com' ([Errno -3] Temporary failure in name resolution)\"))\n"
     ]
    }
   ],
   "source": [
    "# import domolibrary_extensions.google.auth as ga\n",
    "\n",
    "DOCUMENT_ID = \"1j7XsbvFy0xUgGL6i-3LSChKvzSmTZSOyimEt6tQS-Kk\"\n",
    "\n",
    "# generates Credentials object\n",
    "try:\n",
    "    google_auth = ga.GoogleAuth.get_creds_from_env(\n",
    "        credentials_env_key=\"GDOC_KEY\",\n",
    "        token_env_key=\"GDOC_TOKEN\",\n",
    "    )\n",
    "\n",
    "        \n",
    "    content = (\n",
    "        google_auth.service.files()\n",
    "        .export(fileId=DOCUMENT_ID, mimeType=\"application/zip\")\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    download_zip(content, \"../TEST/utils/drive_converter-download_zip\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |exports\n",
    "\n",
    "\n",
    "def download_pptx(\n",
    "    pptx_bytes_content, output_folder, is_convert_to_markdown: bool = True\n",
    "):\n",
    "    \"\"\"save bytes content to a pptx file then converts to markdown\"\"\"\n",
    "\n",
    "    upsert_folder(output_folder)\n",
    "\n",
    "    output_ppt_index = os.path.join(output_folder, \"index.pptx\")\n",
    "\n",
    "    with open(output_ppt_index, \"wb+\") as binary_file:\n",
    "        # Write bytes to file\n",
    "        binary_file.write(pptx_bytes_content)\n",
    "\n",
    "    if is_convert_to_markdown:\n",
    "        pptx2md.convert(\n",
    "            output_ppt_index,\n",
    "            output=os.path.join(output_folder, \"index.md\"),\n",
    "            image_dir=os.path.join(output_folder, \"images\"),\n",
    "        )\n",
    "\n",
    "    return f\"successfully downloaded content to {output_folder}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of download pptx from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using saved token\n",
      "refreshing creds using saved token\n",
      "HTTPSConnectionPool(host='oauth2.googleapis.com', port=443): Max retries exceeded with url: /token (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f829807bc10>: Failed to resolve 'oauth2.googleapis.com' ([Errno -3] Temporary failure in name resolution)\"))\n"
     ]
    }
   ],
   "source": [
    "# | import domolibrary_extensions.google.auth as ga\n",
    "\n",
    "SLIDE_ID = \"1_k4NRraKI1TmHNlpQCuqJrWr6dP7DNracdMCtfN8XlM\"\n",
    "\n",
    "try:\n",
    "    # generates Credentials object\n",
    "    google_auth = ga.GoogleAuth.get_creds_from_env(\n",
    "        credentials_env_key=\"GDOC_KEY\", token_env_key=\"GDOC_TOKEN\"\n",
    "    )\n",
    "\n",
    "    content = (\n",
    "        google_auth.service.files()\n",
    "        .export(\n",
    "            fileId=SLIDE_ID,\n",
    "            mimeType=\"application/vnd.openxmlformats-officedocument.presentationml.presentation\",\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "    download_pptx(content, \"../TEST/utils/drive_converter-download_pptx\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_to_snake_case(text_str):\n",
    "    \"\"\"converts 'snake_case_str' to 'snakeCaseStr'\"\"\"\n",
    "\n",
    "    return text_str.replace(\" \", \"_\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_remove_accents(text_str: str) -> str:\n",
    "    return \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFD\", text_str)\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('est etre', 'kozuscek')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_remove_accents(\"est être\"), convert_str_remove_accents(\"kožušček\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_keep_alphanumeric(text_str) -> str:\n",
    "    pattern = \"[^0-9a-zA-Z_\\s]+\"\n",
    "\n",
    "    return re.sub(pattern, \"\", text_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_file_name(text_str: str) -> str:\n",
    "    \"\"\"convert strings to clean file name or url\"\"\"\n",
    "\n",
    "    return convert_str_keep_alphanumeric(\n",
    "        convert_str_to_snake_case(convert_str_remove_accents(text_str))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('register_snowflake_with_cloud_amplifier', 'kozuscek_and_beast_modes')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_file_name(\"Register Snowflake with Cloud Amplifier\"), convert_str_file_name(\n",
    "    \"Kožušček and Beast Modes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exports\n",
    "def convert_str_to_date(datefield: str) -> dt.datetime:\n",
    "    \"\"\"converts string date to datetime object\"\"\"\n",
    "    return dtu_parse(datefield) if datefield else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 10, 1, 0, 0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_str_to_date(\"2023-10-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export(\"./utils.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
